---
title: "2025-07-22 학습노트"
categories: [학습노트]
date: 2025-07-22
---

# 📚 데이터 & 피처 엔지니어링

---

## 1. 데이터 종류

| **구분**                   | **설명**          | **예시**            |
| -------------------- | -------------- | ------------- |
| **정형(Structured)**       | 표처럼 칸이 딱딱 맞는 것 | 엑셀, DB 테이블    |
| **반정형(Semi-structured)** | 구조는 있지만 표는 아님  | JSON, XML, 로그 |
| **비정형(Unstructured)**    | 아무 구조 없는 것     | 이미지, 텍스트, 음성  |


---

## 2. 수치형 vs 범주형

| **구분**    | **설명**      | **예시**         |
| ----- | ---------- | ---------- |
| **수치형**   | 숫자로 된 데이터  | 키, 몸무게, 나이 |
| **└ 이산형** | 셀 수 있는 숫자  | 사람 수, 주사위  |
| **└ 연속형** | 계속 이어지는 숫자 | 키, 온도      |
| **범주형**   | 이름이나 그룹    | 성별, 혈액형    |
| **└ 순서형** | 순서가 있는 그룹  | 학점, 만족도    |
| **└ 명목형** | 순서 없는 그룹   | 혈액형, 지역    |


---

## 3. 통계 기본

- **공분산**: 두 값이 같이 움직이는 정도 (키 크면 몸무게도 크다)
- **상관계수**: 두 값이 얼마나 비슷하게 움직이는지 -1~+1로 표시
- **고유벡터/고유값**: 데이터가 가장 퍼진 방향과 그 크기

---

## 4. 구글 코랩에서 CSV 불러오기

```python
from google.colab import drive
drive.mount('/content/drive')
import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/파일경로/파일명.csv')
```

---

## 5. 피처 엔지니어링

**머신러닝이나 데이터 분석에서 모델의 성능을 향상시키기 위해 데이터를 가공하는 과정**

### 용어 정리

- **피처**: 예측에 쓰는 정보 (키, 몸무게)
- **타겟**: 예측하고 싶은 값 (집값, 점수)
- **레이블**: 예측하고 싶은 그룹 (스팸/정상)
- **클래스**: 레이블의 종류 (고양이, 강아지)
- **다중공선성**: 여러 피처가 서로 너무 비슷해서(강하게 상관되어서) 모델이 불안정해지는 현상
- **잠재공간**: 데이터의 중요한 패턴만 뽑아낸 숨겨진 공간 (머신러닝 돌리다가 자연스럽게 생기는 공간)
- **구간 분할**: 숫자를 등급이나 그룹으로 나누기 (예: 점수로 A/B/C/D/F)

### 피처 엔지니어링 기법
* **Feature Scaling (스케일링)**
* **Encoding (인코딩)**
* **Missing Value Handling (결측치 처리)**
* **Feature Creation (피처 생성)**
* **Feature Extraction (피처 추출)**
* **Feature Selection (피처 선택)**

---

### 5-1. Feature Scaling (스케일링)

**변수 단위를 맞추는 작업**

| **방법**                  | **설명**       | **적합 상황** |
| ---------------------------- | ------------------------------ | -------------------- |
| **Standardization (표준화)**        | 평균을 0, 표준편차를 1로 변환             | 데이터가 정규분포일 때         |
| **Min-Max Scaling (최소-최대 스케일링)** | 최솟값을 0, 최댓값을 1로 변환해 [0,1]로 조정 | 값의 범위를 맞추고 싶을 때      |
| **Robust Scaling (로버스트 스케일링)**   | 중앙값 기준으로 변환, 이상치에 강함           | 이상치가 많을 때            |
| **Log Transformation (로그 변환)**   | 큰 값의 영향을 줄여줌                   | 오른쪽으로 치우친 분포         |

---

### 5-2. Encoding (인코딩)

**범주형 데이터를 수치로 바꾸는 것**

| **방법**         | **적합 상황**           | 	**예시**                |
|--------------|---------------------|---------------------|
| **Label Encoding (레이블 인코딩)**| 순서 있는 그룹      | 학점: A→0, B→1, ...|
| **One-Hot Encoding (원-핫 인코딩)** | 순서 없는 그룹      | 색깔: 빨강→[1,0,0] 파랑→[0,1,0] |
| **Target Encoding (타겟 인코딩)**  | 그룹이 너무 많을 때 | 지역별 평균 집값    |

> **주의**: 원-핫은 그룹 많으면 너무 복잡, 타겟 인코딩은 과적합 위험!

---

### 5-3. Missing Value Handling (결측치 처리)

**비어있는 값을 적절히 채우거나 제거**

#### 결측치 패턴

| **패턴**   | **의미**              | **처리 난이도** |
| ---- | --------------- | ------ |
| MCAR | 완전 무작위 결측       | 쉬움     |
| MAR  | 다른 변수에 따라 결측 발생 | 중간     |
| MNAR | 자기 변수 자체가 결측 원인 | 어려움     |


#### 결측치 처리 전략

| **전략**                             | **특징**              | **적합 상황**          |
| ------------------------------ | --------------- | -------------- |
| **Drop (삭제)**                             | 행/열 제거          | 결측 적을 때        |
| **Mean/Median Imputation (평균/중앙값)**                      | 수치형 대체 (단순)     | 빠르게 처리할 때      |
| **Mode Imputation (최빈값)**                         | 범주형 대체          | 카테고리형일 때       |
| **Interpolation (보간)**                             | 앞뒤 값으로 채움 (시계열) | 시간 데이터         |
| **Predictive Imputation (예측 대체)**                          | 모델로 예측해서 채움     | 정확도 중요할 때      |
| **Special Value/Masking (특수값/마스킹)** | 결측 자체도 정보로 사용   | 결측 자체도 의미 있을 때 |

---

### 5-4. Feature Creation (피처 생성)

**도메인 지식을 활용해서 직접 새로운 변수를 만듦**

| **종류**       | **설명**          | **예시**            |
| -------- | ------------- | ------------- |
| **Numeric Combination (수치형 조합)**   | 수치 간 곱/합 등    | 가격 × 수량 = 총액  |
| **Categorical Combination (범주형 조합)**   | 범주 결합         | 성별+지역         |
| **Time Derivation (시간 파생)** | 날짜/시간 활용      | 요일, 주말 여부     |
| **Binary Variable (이진 변수)**    | 조건으로 0/1 구분   | 연봉 > 5000 → 1 |
| **Group Statistics (그룹 통계)**    | 그룹별 평균, 최대값 등 | 지역별 평균 소득     |


---

### 5-5. Feature Extraction (피처 추출)

**기존 피처들을 조합해서 새로운 변수로 바꾸는 것**

| **방법**  | **설명**          | **예시**               |
| --- | -------------- | ---------------- |
| **PCA: Principal Component Analysis (주성분 분석)** | 손실 최소화 차원 축소   | 점수 100개 → 2개로 요약 |
| **LDA: Linear Discriminant Analysis (선형 판별 분석)** | 그룹 구분에 초점 둔 축소 | 고양이/강아지 구분       |

---

### 5-6. Feature Selection (피처 선택)

**많은 변수를 다 쓰면 노이즈가 많아지니까 중요한 변수만 뽑는 작업**

#### 필터 기법
- **상관계수**: 타겟과 비슷하게 움직이는 피처만 선택
- **카이제곱**: 범주형끼리 연관성 있는 것만 선택
- **분산 임계값**: 값이 거의 안 바뀌는 피처 제거

#### 래퍼 기법
- **순방향 선택**: 하나씩 추가해서 성능 좋아지면 선택
- **역방향 제거**: 다 넣고 하나씩 빼서 성능 나빠지면 다시 넣음
- **재귀적 제거(RFE)**: 중요도 낮은 것부터 반복적으로 제거

#### 임베디드 기법

| **방법**            | **설명**               | **장단점**       | **예시**        |
| ------------- | ------------------- | --------- | --------- |
| **Lasso (L1)**    | 중요도 낮은 피처 계수 0으로 설정 | 해석 쉬움     | 집값 예측     |
| **Ridge (L2)**    | 모든 피처 계수 작게 조정      | 다중공선성 완화  | 회귀모델      |
| **Elastic Net**  | L1 + L2 결합          | 조정 복잡     | 유전자 예측    |
| **Random Forest** | 트리 기반 중요도 평균        | 비선형 대응 가능 | 복잡한 분류/회귀 |

##### 정규화 수식
- **L1**: 계수 절댓값 합 제한
- **L2**: 계수 제곱합 제한

---

## 7. 샘플링 기법 & 데이터 처리 방식

### 언더샘플링 기법

| **방법**                    | **설명**                             |
|-----------------------|--------------------------------|
| **Random**               | 많은 클래스에서 샘플을 무작위로 일부 삭제       |
| **Tomek Links**          | 가까운 다른 클래스 샘플 쌍을 찾아 제거          |
| **OSS (One-Sided Selection)** | 겹치는 애매한 샘플만 남기고 나머지는 삭제      |
| **CNN (Condensed NN)**   | 분류에 꼭 필요한 핵심 샘플만 남기고 압축       |

---

### 오버샘플링 기법

| **방법**               | **설명**                           |
|--------------------|------------------------------|
| **Random**             | 소수 클래스 샘플을 단순 복제                      |
| **SMOTE**              | 비슷한 샘플 사이에 새로운 샘플을 만들어 추가           |
| **ADASYN**             | 구분이 어려운 샘플 주변에 새 샘플을 더 많이 생성         |
| **Borderline-SMOTE**   | 다른 클래스와 헷갈릴 만한 샘플 주변에 새 샘플 생성        |
| **KMeans-SMOTE**       | 비슷한 샘플끼리 묶은 그룹 중심에서 새 샘플 생성          |

---

### 데이터 처리 방식: ETL vs ELT

| **방법** | **정의** | **적합 환경** |
|--------|------------------------|------------------------------------------------------|---------------|
| **ETL (Extract, Transform, Load)** | 추출 → 외부에서 변환 → 저장소에 넣음 | **자체 서버에 구축된 데이터베이스 시스템** |
| **ELT (Extract, Load, Transform)** | 추출 → 저장소에 넣고 → 저장소 안에서 처리 | **클라우드 기반 저장소 (예: BigQuery, Redshift)** |

- **Extract**: 원본 데이터를 추출해서 가져옴 
- **Transform**: 데이터 정제, 형변환, 집계 등 가공 수행  
- **Load**: 파일 또는 테이블로 저장

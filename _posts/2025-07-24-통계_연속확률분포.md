---
title: "통계 - 연속 확률분포"
categories: [통계]
math: true
---

# 📚 연속 확률분포(Discrete)

---

## ND (Normal Distribution, 정규분포)

**보편적인 분포라서 맨 앞에 Normal이 붙었다**  

평균 근처에 학생들이 몰려 있고, 만점이나 빵점은 흔치 않다.  
이처럼 ‘중간이 많고 양끝이 드문’ 데이터를 그래프로 그리면  
**종(bell)처럼 생긴 곡선**이 나오는데, 이것이 바로 정규분포($\mathcal{N}$)이다.

---

**정규분포($\mathcal{N}$) 사진**

![정규분포 예시](https://upload.wikimedia.org/wikipedia/commons/8/8c/Standard_deviation_diagram.svg)

*이렇게 종 모양처럼 생겨서 벨 곡선(bell curve)이라고 부릅니다.*  
*(중간이 가장 높고, 양 옆으로 갈수록 낮아짐)*

---

- 평균($\mu$)이 그래프에서 종 곡선의 정가운데가 되고,

- 표준편차($\sigma$): 평균 근처에 얼마나 많이 몰려 있느냐, 아니면 퍼져 있느냐를 나타냄 
  - 모두가 170cm에 붙어 있다면 → 표준편차가 작다 (날씬한 종!)  
  - 어떤 애는 130cm, 어떤 애는 210cm → 표준편차가 크다 (뚱뚱한 종!)

---

**68-95-99.7 법칙**

정규분포($\mathcal{N}$)에서는 다음과 같은 특징이 있다:
 
$$
\begin{aligned}
\text{평균} \pm 1\sigma &\quad \rightarrow \quad \text{전체의 약 68\%} \\
\text{평균} \pm 2\sigma &\quad \rightarrow \quad \text{전체의 약 95\%} \\
\text{평균} \pm 3\sigma &\quad \rightarrow \quad \text{전체의 약 99.7\%}
\end{aligned}
$$

“평균에서 $3\sigma$ 이상 멀리 있는 값은 정말 희귀하다!”  
이런 식으로 표현이 가능하다.

---

### 표준정규분포 (Standard Normal Distribution)

정규분포 중에서 **평균이 0, 표준편차가 1**인 특별한 분포를 **표준정규분포**라고 한다.

- **기호:** $Z \sim \mathcal{N}(0, 1)$
- **확률밀도함수(PDF):**
  $$
  f(z) = \frac{1}{\sqrt{2\pi}} e^{-z^2/2}
  $$
- **특징:**
  - 평균이 0, 표준편차가 1
  - 모든 정규분포는 $Z$-score로 변환하면 표준정규분포가 됨
  - 표준정규분포표(누적확률표)를 통해 확률을 쉽게 찾을 수 있음

#### 표준정규분포표

| $z$  | 0.00 | 0.01 | 0.02 | 0.03 | 0.04 | 0.05 | 0.06 | 0.07 | 0.08 | 0.09 |
|------|------|------|------|------|------|------|------|------|------|------|
| 0.0  | 0.5000 | 0.5040 | 0.5080 | 0.5120 | 0.5160 | 0.5199 | 0.5239 | 0.5279 | 0.5319 | 0.5359 |
| 0.1  | 0.5398 | 0.5438 | 0.5478 | 0.5517 | 0.5557 | 0.5596 | 0.5636 | 0.5675 | 0.5714 | 0.5753 |
| 0.2  | 0.5793 | 0.5832 | 0.5871 | 0.5910 | 0.5948 | 0.5987 | 0.6026 | 0.6064 | 0.6103 | 0.6141 |
| 0.3  | 0.6179 | 0.6217 | 0.6255 | 0.6293 | 0.6331 | 0.6368 | 0.6406 | 0.6443 | 0.6480 | 0.6517 |
| 0.4  | 0.6554 | 0.6591 | 0.6628 | 0.6664 | 0.6700 | 0.6736 | 0.6772 | 0.6808 | 0.6844 | 0.6879 |
| 0.5  | 0.6915 | 0.6950 | 0.6985 | 0.7019 | 0.7054 | 0.7088 | 0.7123 | 0.7157 | 0.7190 | 0.7224 |
| 0.6  | 0.7257 | 0.7291 | 0.7324 | 0.7357 | 0.7389 | 0.7422 | 0.7454 | 0.7486 | 0.7517 | 0.7549 |
| 0.7  | 0.7580 | 0.7611 | 0.7642 | 0.7673 | 0.7704 | 0.7734 | 0.7764 | 0.7794 | 0.7823 | 0.7852 |
| 0.8  | 0.7881 | 0.7910 | 0.7939 | 0.7967 | 0.7995 | 0.8023 | 0.8051 | 0.8078 | 0.8106 | 0.8133 |
| 0.9  | 0.8159 | 0.8186 | 0.8212 | 0.8238 | 0.8264 | 0.8289 | 0.8315 | 0.8340 | 0.8365 | 0.8389 |
| 1.0  | 0.8413 | 0.8438 | 0.8461 | 0.8485 | 0.8508 | 0.8531 | 0.8554 | 0.8577 | 0.8599 | 0.8621 |
| 1.1  | 0.8643 | 0.8665 | 0.8686 | 0.8708 | 0.8729 | 0.8749 | 0.8770 | 0.8790 | 0.8810 | 0.8830 |
| 1.2  | 0.8849 | 0.8869 | 0.8888 | 0.8907 | 0.8925 | 0.8944 | 0.8962 | 0.8980 | 0.8997 | 0.9015 |
| 1.3  | 0.9032 | 0.9049 | 0.9066 | 0.9082 | 0.9099 | 0.9115 | 0.9131 | 0.9147 | 0.9162 | 0.9177 |
| 1.4  | 0.9192 | 0.9207 | 0.9222 | 0.9236 | 0.9251 | 0.9265 | 0.9279 | 0.9292 | 0.9306 | 0.9319 |
| 1.5  | 0.9332 | 0.9345 | 0.9357 | 0.9370 | 0.9382 | 0.9394 | 0.9406 | 0.9418 | 0.9429 | 0.9441 |
| 1.6  | 0.9452 | 0.9463 | 0.9474 | 0.9484 | 0.9495 | 0.9505 | 0.9515 | 0.9525 | 0.9535 | 0.9545 |
| 1.7  | 0.9554 | 0.9564 | 0.9573 | 0.9582 | 0.9591 | 0.9599 | 0.9608 | 0.9616 | 0.9625 | 0.9633 |
| 1.8  | 0.9641 | 0.9649 | 0.9656 | 0.9664 | 0.9671 | 0.9678 | 0.9686 | 0.9693 | 0.9699 | 0.9706 |
| 1.9  | 0.9713 | 0.9719 | 0.9726 | 0.9732 | 0.9738 | 0.9744 | 0.9750 | 0.9756 | 0.9761 | 0.9767 |
| 2.0  | 0.9772 | 0.9778 | 0.9783 | 0.9788 | 0.9793 | 0.9798 | 0.9803 | 0.9808 | 0.9812 | 0.9817 |
| 2.1  | 0.9821 | 0.9826 | 0.9830 | 0.9834 | 0.9838 | 0.9842 | 0.9846 | 0.9850 | 0.9854 | 0.9857 |
| 2.2  | 0.9861 | 0.9864 | 0.9868 | 0.9871 | 0.9875 | 0.9878 | 0.9881 | 0.9884 | 0.9887 | 0.9890 |
| 2.3  | 0.9893 | 0.9896 | 0.9898 | 0.9901 | 0.9904 | 0.9906 | 0.9909 | 0.9911 | 0.9913 | 0.9916 |
| 2.4  | 0.9918 | 0.9920 | 0.9922 | 0.9925 | 0.9927 | 0.9929 | 0.9931 | 0.9932 | 0.9934 | 0.9936 |
| 2.5  | 0.9938 | 0.9940 | 0.9941 | 0.9943 | 0.9945 | 0.9946 | 0.9948 | 0.9949 | 0.9951 | 0.9952 |
| 2.6  | 0.9953 | 0.9955 | 0.9956 | 0.9957 | 0.9959 | 0.9960 | 0.9961 | 0.9962 | 0.9963 | 0.9964 |
| 2.7  | 0.9965 | 0.9966 | 0.9967 | 0.9968 | 0.9969 | 0.9970 | 0.9971 | 0.9972 | 0.9973 | 0.9974 |
| 2.8  | 0.9974 | 0.9975 | 0.9976 | 0.9977 | 0.9977 | 0.9978 | 0.9979 | 0.9979 | 0.9980 | 0.9981 |
| 2.9  | 0.9981 | 0.9982 | 0.9982 | 0.9983 | 0.9984 | 0.9984 | 0.9985 | 0.9985 | 0.9986 | 0.9986 |
| 3.0  | 0.9987 | 0.9987 | 0.9987 | 0.9988 | 0.9988 | 0.9989 | 0.9989 | 0.9989 | 0.9990 | 0.9990 |

---

## Student’s T-Distribution (T분포)

**샘플 수가 적고 분산도 모를 때 평균을 비교하기 위한 분포**  
→ 정규분포처럼 생겼지만 **꼬리가 더 두꺼워서** 작은 표본에 유리함

- **언제 쓰나?**
  - 표본 수가 작고 ($n < 30$ 정도)
  - 모집단 분산 $\sigma^2$를 모름
  - 평균이 어떤 값과 **통계적으로 다른지** 검정할 때

- **통계량 공식**

  $$
  t = \frac{\bar{X} - \mu_0}{S / \sqrt{n}}, \quad t \sim t_{n - 1}
  $$

  예: 표본평균 $\bar{X} = 5.2$, 표본표준편차 $S = 1.5$, 표본크기 $n = 10$,  
  비교 대상 $\mu_0 = 5$일 때:

  $$
  t = \frac{5.2 - 5}{1.5 / \sqrt{10}} \approx 0.42
  $$

  → 이 $t$값이 통계적으로 유의한지 **t-분포표나 p-value**로 확인

- **기댓값**: 0 (단, $n > 1$)  
- **분산**: $\dfrac{n - 1}{n - 3}$ (단, $n > 2$)

> 표본 수가 많아질수록 **정규분포에 가까워진다**  
> 평균 비교를 위한 **t-검정의 핵심 분포**

---

## Exponential Distribution (지수분포)

**“다음 사건이 언제 일어날까?”를 확률로 표현한 분포**  
예:  
- 버스가 언제 도착할까?  
- 다음 손님은 몇 분 뒤에 올까?  

- **매개변수**: $\lambda > 0$  
  → 단위 시간당 평균 몇 번 일어나는지 (발생률)

- **확률밀도함수(PDF)**:

  $$
  f(x;\lambda) =
    \begin{cases}
      \lambda e^{-\lambda x} & x \ge 0 \\
      0 & x < 0
    \end{cases}
  $$

  → $x$분이 지났을 때 **아직 사건이 안 일어났을 확률**은  
  $$P(X > x) = e^{-\lambda x}$$  
  → 시간이 지날수록 점점 사건이 일어날 확률이 줄어든다.

- **예시**  
  어떤 동네 버스는 **평균 10분마다 1대**씩 온다.  
  즉, $\lambda = \frac{1}{10} = 0.1$

  “7분 안에 버스가 올 확률”은?

  $$
  P(X \le 7) = 1 - e^{-0.1 \times 7} = 1 - e^{-0.7} \approx 0.5034
  $$

  → 기다린 지 7분이 되었을 때, **절반 정도의 확률로 버스가 도착**했다는 의미!

- **기댓값**: $\operatorname{E}[X] = \frac{1}{\lambda}$  
  → 평균 대기 시간  
- **분산**: $\operatorname{Var}(X) = \frac{1}{\lambda^2}$

- **특징**  
  - **메모리리스 (기억 없음)**  
    → 이미 10분 기다렸다고 해도, 앞으로 또 10분 기다릴 수도 있다.  
    → 과거의 대기 시간은 미래에 아무 영향이 없다!
  - **포아송 분포와 연결**  
    - 포아송: “1시간 동안 몇 건 일어날까?”  
    - 지수분포: “다음 사건까지 얼마나 걸릴까?”

> “포아송은 **개수**를, 지수는 **시간**을 다룬다.”  
> 둘은 **사건의 흐름을 입체적으로 바라보는 두 시선**이다.

---

### Gamma Distribution (감마분포)

**지수분포 여러 개를 더하면 감마분포가 된다!**  
예를 들어, 고객이 올 때까지의 시간은 **지수분포**,  
**3명 고객이 올 때까지의 총 대기 시간**은 **감마분포**를 따른다.

- **모수**:  
  - $k$: 모양(shape), 몇 번 기다리는지 → 고객 수  
  - $\theta$: 평균 대기 시간 (scale)

- **확률밀도함수 (PDF)**:
  $$
  f(x; k, \theta) = 
  \frac{1}{\Gamma(k)\,\theta^k}\,x^{k-1}e^{-x/\theta}, 
  \quad x > 0
  $$

- **예시**  
  평균적으로 3분마다 고객이 오고($\theta = 3$),  
  2번째 고객까지 기다릴 때($k = 2$),  
  **4분이 지나 있을 확률 밀도**는?

  $$
  f(4; 2, 3) 
  = \frac{1}{\Gamma(2)\cdot 3^2} \cdot 4^{1} \cdot e^{-4/3}
  = \frac{4}{9} \cdot e^{-1.33\ldots} 
  \approx 0.105
  $$

  → 즉, "딱 4분째에 두 번째 고객이 도착할 가능성"이 가장 높은 시점은 아님.  
  → 감마분포는 **첫 번째, 두 번째, 세 번째… 고객이 오기까지의 누적 시간**을 모델링!

- **기댓값**: $\operatorname{E}[X]=k\theta$  
- **분산**: $\operatorname{Var}(X)=k\theta^2$  

---

### Weibull Distribution (웨이블 분포)

**"시간이 지날수록 고장날 확률이 바뀐다면?"**  
웨이블 분포는 **고장률이 시간에 따라 달라질 수 있는 상황**을 모델링하는 데 쓰인다.  
기계 부품, 전자제품, 사람의 수명처럼 — 시간이 핵심인 문제에 딱이다.

- **모수**
  - $k$: **형태(shape)** — 시간이 지남에 따라 고장 확률이 어떻게 변하는지  
  - $\lambda$: **척도(scale)** — 고장이 대체로 언제쯤 일어나는지 조절 (시간 단위 느낌)

- **확률밀도함수(PDF)**  
  $$ 
  f(x; k, \lambda) = 
  \frac{k}{\lambda} \left( \frac{x}{\lambda} \right)^{k-1} e^{-(x/\lambda)^k}, \quad x \ge 0 
  $$

- **예시**  
  어떤 부품이 **대체로 5시간쯤에 고장** 나고,  
  시간이 갈수록 고장 확률이 **점점 증가**한다면:  
  $k = 2$, $\lambda = 5$라고 두고 $x = 3$시간일 때의 고장 가능성은:

  $$
  f(3; 2, 5) = \frac{2}{5} \cdot \left(\frac{3}{5}\right)^1 \cdot e^{-(3/5)^2}
           \approx 0.166
  $$

- **기댓값** (평균 수명):  
  $$
  \operatorname{E}[X] = \lambda \cdot \Gamma\left(1 + \frac{1}{k}\right)
  $$

- **분산**:  
  $$
  \operatorname{Var}(X) = \lambda^2 \left[
    \Gamma\left(1 + \frac{2}{k}\right)
    - \left(\Gamma\left(1 + \frac{1}{k}\right)\right)^2
  \right]
  $$

- **형태 모수 $k$의 의미**  
  - $k < 1$ → 시간이 지날수록 고장 확률이 **줄어듦** (초기 불량 많음!)  
  - $k = 1$ → 고장 확률이 **항상 일정** → **지수분포**랑 같음  
  - $k > 1$ → 시간이 지날수록 고장 확률이 **점점 증가** (노화하는 부품)

- **사용 사례**  
  - 하드디스크가 언제 죽을지  
  - 사람이 약 복용 후 효과가 나타나는 시간  
  - 전자제품의 고장률 분석  
  - 생존 분석, 보험 수명 모델링 등  

> 웨이블 분포는 “언제 고장날지 모른다”는 상황에서  
> **시간과 위험의 관계를 수식으로 말해주는 분포**다.

---

### Beta Distribution (베타분포)

**“확률도 불확실하다면, 확률로 생각하자!”**  
어떤 사건의 성공 확률 $p$를 모르고, 그 $p$가 어떤 값일지 **확률분포로 나타낸 것**이 베타분포다.  
(예: 이 동전이 앞면이 나올 확률은 과연 얼마일까?)

- **모수**: $\alpha$ (앞면 나온 횟수 + 1), $\beta$ (뒷면 나온 횟수 + 1)

- **확률밀도함수(PDF)**:
  $$
  f(p) = \frac{1}{B(\alpha, \beta)}\,p^{\alpha - 1}(1 - p)^{\beta - 1}
  $$

- **예시**  
  동전을 4번 던져 **앞면 1번, 뒷면 3번** 나왔다면,  
  베타분포의 모수는 $\alpha = 1 + 1 = 2$, $\beta = 3 + 1 = 4$

  $$
  f(p) = \frac{1}{B(2,4)}\,p(1 - p)^3 = 60\,p(1 - p)^3
  $$

  → $p$가 0.2~0.4 정도일 가능성이 가장 높고,  
  → 극단값($p=0$ 또는 $1$)은 가능성이 낮다.

- **기댓값**: $\displaystyle \frac{\alpha}{\alpha + \beta}$  
  → 이 예시에선 $\frac{2}{6} = 0.333$  
- **분산**: $\displaystyle \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}$

- **특징**  
  - $p \in (0,1)$ 구간에서 정의됨  
  - 베르누이/이항분포의 **사전분포(prior)**로 자주 등장  
  - $\alpha = \beta = 1$이면 **균등분포**

---
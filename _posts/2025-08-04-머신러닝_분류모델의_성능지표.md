---
title: "머신러닝 #7 - 분류모델의 성능지표"
categories: [머신러닝]
math: true
---

# 📚 분류모델의 성능지표

---

## 🔧 1. 왜 알아야 하는가?

분류 모델은 이메일 스팸 탐지, 질병 진단, 이미지 분류 등 일상적이고 중요한 문제에 사용됩니다.
**모델이 얼마나 잘 작동하는지를 평가하지 않으면, 실제 환경에서 심각한 오류**(예: 암인데 정상이라고 판단)로 이어질 수 있습니다.
성능지표는 단순한 ‘정답률’ 이상으로, **무엇이 잘 되고 무엇이 잘못되고 있는지를 구체적으로 보여주는 도구**입니다.

---

## 🧭 2. 전체 구조

성능지표는 크게 아래와 같이 나눌 수 있습니다:

1. **기본 개념**: 정답과 예측을 비교하는 혼동행렬(confusion matrix)
2. **이진 분류 지표** (두 클래스: 예/아니오)

   * 정확도 (Accuracy)
   * 오분류율 (Error Rate)
   * 정밀도 (Precision)
   * 재현율 / 민감도 (Recall, Sensitivity)
   * 특이도 (Specificity)
   * F1 Score
   * ROC-AUC
3. **다중 클래스 지표**

   * 매크로 평균 vs 마이크로 평균
4. **비정형 지표**

   * Log loss, Matthews correlation coefficient 등 (고급)

---

## 📐 3. 개념 설명

### 3.1 혼동행렬 (Confusion Matrix)

| 실제 / 예측 | 양성 (Positive) | 음성 (Negative) |
| ------- | ------------- | ------------- |
| **양성**  | TP            | FN            |
| **음성**  | FP            | TN            |

* **TP (True Positive)**: 실제도 양성이고, 예측도 양성
* **FP (False Positive)**: 실제는 음성인데 예측은 양성 (거짓 경보)
* **FN (False Negative)**: 실제는 양성인데 예측은 음성 (놓친 케이스)
* **TN (True Negative)**: 실제도 음성이고, 예측도 음성

### 3.2 주요 성능 지표 (이진 분류 기준)

* **정확도 (Accuracy)** = (TP + TN) / (혼동행렬 전체 합계)

  * 전체 중 맞춘 비율
  * 클래스가 불균형한 경우 신뢰하기 어려움 (ex. 95%가 정상인데 전부 정상이라 해도 Accuracy 95%)

* **오분류율 (Error Rate)** = 1 - Accuracy

  * 전체 중 틀린 비율

* **정밀도 (Precision)** = TP / (TP + FP)

  * 예측한 것 중에 진짜로 맞은 비율 (스팸이라고 한 것 중 실제 스팸)
  * 잘못 긍정하면 곤란한 경우에 중요

* **재현율 / 민감도 (Recall, Sensitivity)** = TP / (TP + FN)

  * 실제 양성 중에서 놓치지 않고 잡은 비율 (전체 스팸 중에서 잘 잡아낸 비율)
  * FN(거짓 음성)을 줄이는 데 중점. 암 진단처럼 **놓치면 안 되는 경우에 중요**

* **특이도 (Specificity)** = TN / (TN + FP)

  * 실제 음성을 잘 걸러내는 능력
  * 거짓 양성(FP)을 줄이는 게 중요한 경우 사용
  * 예시) 정상인을 오진하지 않도록 할 때 중요

* **F1 Score** = 2 × (Precision × Recall) / (Precision + Recall)

  * 정밀도와 재현율의 조화 평균. 둘 사이의 균형이 중요할 때 사용
  * F1은 TP에만 기반하고 TN은 고려하지 않기 때문에 데이터셋 전체의 성능을 반영하지는 않음.

* **ROC-AUC (Area Under Curve)**

  * 분류기의 확신(confidence)에 따라 성능을 평가
  * 0.5 = 랜덤, 1.0 = 완벽
  * 불균형 데이터셋에서 비교적 신뢰 가능

---

## 🎯 4. 예시로 이해해보기

### 예: 스팸 메일 분류기

* 1000개의 메일 중 100개가 스팸
* 모델이 80개를 스팸이라 예측했는데, 그 중 60개가 진짜 스팸
* 그리고 실제 스팸 중 20개는 놓쳤다

→ Confusion Matrix

* TP = 60
* FP = 20
* FN = 40
* TN = 880

→ 지표 계산:

* **Accuracy** = (60 + 880) / 1000 = 94%
* **Precision** = 60 / (60 + 20) = 75%
* **Recall** = 60 / (60 + 40) = 60%
* **F1** ≈ 66.7%

이 경우, 정확도만 보면 모델이 매우 뛰어나 보이지만, 스팸을 놓치는 경우(FN)가 많아서 실제로는 개선이 필요합니다.

---

## ⚠️ 5. 주의할 점

* 클래스 불균형 문제에선 Accuracy는 신뢰할 수 없음
* F1-score도 어떤 상황에선 과대평가될 수 있음
* **비즈니스 맥락**에 따라 Precision과 Recall의 중요도가 다르다

  * 예: **암 진단** → Recall 중요
  * 예: **광고 클릭 예측** → Precision 중요

---

## 🧩 6. 요약 정리

* 분류 모델은 성능을 제대로 평가해야 실전에서 신뢰할 수 있다.
* Accuracy는 기본적인 지표지만, 그 외에도 Precision, Recall, F1, ROC-AUC 등을 상황에 맞게 사용해야 한다.
* 무엇을 더 중요시할지는 문제의 특성에 따라 달라진다.

---